{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense  \n",
    "from keras.layers import LSTM  \n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('modeling/Data/Data Given/MMM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/2009</td>\n",
       "      <td>57.549999</td>\n",
       "      <td>59.389999</td>\n",
       "      <td>57.520000</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>45.690918</td>\n",
       "      <td>5313900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/5/2009</td>\n",
       "      <td>58.790001</td>\n",
       "      <td>59.090000</td>\n",
       "      <td>58.110001</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>45.158264</td>\n",
       "      <td>3768800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/6/2009</td>\n",
       "      <td>58.740002</td>\n",
       "      <td>59.810001</td>\n",
       "      <td>58.610001</td>\n",
       "      <td>59.189999</td>\n",
       "      <td>45.690918</td>\n",
       "      <td>4966200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/7/2009</td>\n",
       "      <td>58.610001</td>\n",
       "      <td>58.959999</td>\n",
       "      <td>57.580002</td>\n",
       "      <td>58.070000</td>\n",
       "      <td>44.826347</td>\n",
       "      <td>4598100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/8/2009</td>\n",
       "      <td>57.680000</td>\n",
       "      <td>58.709999</td>\n",
       "      <td>57.450001</td>\n",
       "      <td>58.580002</td>\n",
       "      <td>45.220032</td>\n",
       "      <td>3944900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date       Open       High        Low      Close  Adj Close     Volume\n",
       "0  1/2/2009  57.549999  59.389999  57.520000  59.189999  45.690918  5313900.0\n",
       "1  1/5/2009  58.790001  59.090000  58.110001  58.500000  45.158264  3768800.0\n",
       "2  1/6/2009  58.740002  59.810001  58.610001  59.189999  45.690918  4966200.0\n",
       "3  1/7/2009  58.610001  58.959999  57.580002  58.070000  44.826347  4598100.0\n",
       "4  1/8/2009  57.680000  58.709999  57.450001  58.580002  45.220032  3944900.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = data.dropna()\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = d2.iloc[:,4:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "trans_mm= scaler.fit_transform(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_set = []  \n",
    "labels = []  \n",
    "for i in range(60, len(mm)):  \n",
    "    features_set.append(trans_mm[i-60:i, 0])\n",
    "    labels.append(trans_mm[i, 0])\n",
    "features_set, labels = np.array(features_set), np.array(labels)\n",
    "features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.60\n",
    "\n",
    "train_size = int(len(trans_mm) * TRAIN_SIZE)\n",
    "test_size = len(trans_mm) - train_size\n",
    "train, test = trans_mm[0:train_size, :], trans_mm[train_size:len(trans_mm), :]\n",
    "\n",
    "def create_dataset(dataset, window_size = 1):\n",
    "    data_X, data_Y = [], []\n",
    "    for i in range(len(trans_mm) - window_size - 1):\n",
    "        a = dataset[i:(i + window_size), 0]\n",
    "        data_X.append(a)\n",
    "        data_Y.append(trans_mm[i + window_size, 0])\n",
    "    return(np.array(data_X), np.array(data_Y))\n",
    "window_size = 1\n",
    "train_X, train_Y = create_dataset(train, window_size)\n",
    "test_X, test_Y = create_dataset(test, window_size)\n",
    "\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], 1, test_X.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(train_X, train_Y, window_size = 1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(4, \n",
    "                   input_shape = (1, window_size)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = \"mean_squared_error\", \n",
    "                  optimizer = \"adam\")\n",
    "    model.fit(train_X, \n",
    "              train_Y, \n",
    "              epochs = 100, \n",
    "              batch_size = 1, \n",
    "              verbose = 2)\n",
    "    \n",
    "    return(model)\n",
    "\n",
    "# Fit the first model.\n",
    "model1 = fit_model(train_X, train_Y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_score(model, X, Y):\n",
    "    # Make predictions on the original scale of the data.\n",
    "    pred = scaler.inverse_transform(model.predict(X))\n",
    "    # Prepare Y data to also be on the original scale for interpretability.\n",
    "    orig_data = scaler.inverse_transform([Y])\n",
    "    # Calculate RMSE.\n",
    "    score = math.sqrt(mean_squared_error(orig_data[0], pred[:, 0]))\n",
    "    return(score, pred)\n",
    "\n",
    "rmse_train, train_predict = predict_and_score(model1, train_X, train_Y)\n",
    "rmse_test, test_predict = predict_and_score(model1, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start with training predictions.\n",
    "train_predict_plot = np.empty_like(trans_mm)\n",
    "train_predict_plot[:, :] = np.nan\n",
    "train_predict_plot[window_size:len(train_predict) + window_size, :] = train_predict\n",
    "\n",
    "# Add test predictions.\n",
    "test_predict_plot = np.empty_like(trans_mm)\n",
    "test_predict_plot[:, :] = np.nan\n",
    "test_predict_plot[len(train_predict) + (window_size * 2) + 1:len(trans_mm) - 1, :] = test_predict\n",
    "\n",
    "# Create the plot.\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(scaler.inverse_transform(trans_mm), label = \"True value\")\n",
    "plt.plot(train_predict_plot, label = \"Training set prediction\")\n",
    "plt.plot(test_predict_plot, label = \"Test set prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inputs= d2.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = test_inputs.reshape(-1,1)  \n",
    "test_inputs = scaler.transform(test_inputs) \n",
    "test_features = []  \n",
    "for i in range(60, len(test_inputs)):  \n",
    "    test_features.append(test_inputs[i-60:i, 0])\n",
    "test_features = np.array(test_features)  \n",
    "test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2456, 60, 1), (2456, 60, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_set.shape,test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(LSTM(units=50, return_sequences=True))  \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True))  \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50))  \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1))  \n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 0.0176\n",
      "Epoch 2/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0027\n",
      "Epoch 3/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0028\n",
      "Epoch 4/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0024\n",
      "Epoch 5/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0022\n",
      "Epoch 6/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0022\n",
      "Epoch 7/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0021\n",
      "Epoch 8/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0022\n",
      "Epoch 9/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0017\n",
      "Epoch 10/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0018\n",
      "Epoch 11/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0019\n",
      "Epoch 12/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0017\n",
      "Epoch 13/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0016\n",
      "Epoch 15/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0017\n",
      "Epoch 17/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0016\n",
      "Epoch 18/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0014\n",
      "Epoch 19/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0015\n",
      "Epoch 20/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 0.0014\n",
      "Epoch 21/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0013\n",
      "Epoch 22/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0014\n",
      "Epoch 23/100\n",
      "2456/2456 [==============================] - 18s 8ms/step - loss: 0.0015\n",
      "Epoch 24/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0013\n",
      "Epoch 25/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0014\n",
      "Epoch 26/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0012\n",
      "Epoch 27/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0012\n",
      "Epoch 28/100\n",
      "2456/2456 [==============================] - 21s 8ms/step - loss: 0.0011\n",
      "Epoch 29/100\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 0.0012\n",
      "Epoch 30/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0012\n",
      "Epoch 31/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 0.0010\n",
      "Epoch 33/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0010\n",
      "Epoch 34/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 0.0010\n",
      "Epoch 35/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 9.7123e-04\n",
      "Epoch 36/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 0.0011\n",
      "Epoch 37/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 9.3559e-04\n",
      "Epoch 39/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 9.5031e-04\n",
      "Epoch 40/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 9.4982e-04\n",
      "Epoch 41/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.5426e-04\n",
      "Epoch 42/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 9.8473e-04\n",
      "Epoch 43/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 9.4216e-04\n",
      "Epoch 44/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 9.4823e-04\n",
      "Epoch 45/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 8.0614e-04\n",
      "Epoch 46/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.9231e-04\n",
      "Epoch 47/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.8306e-04\n",
      "Epoch 48/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.1916e-04\n",
      "Epoch 49/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.2174e-04\n",
      "Epoch 50/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.1765e-04\n",
      "Epoch 51/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 8.1476e-04\n",
      "Epoch 52/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 9.0867e-04\n",
      "Epoch 53/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 7.8510e-04\n",
      "Epoch 54/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.9450e-04\n",
      "Epoch 55/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.7081e-04\n",
      "Epoch 56/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.6772e-04\n",
      "Epoch 57/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.5828e-04\n",
      "Epoch 58/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 7.6157e-04\n",
      "Epoch 59/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 7.0676e-04\n",
      "Epoch 60/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 6.8923e-04\n",
      "Epoch 61/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 7.5766e-04\n",
      "Epoch 62/100\n",
      "2456/2456 [==============================] - 20s 8ms/step - loss: 6.1459e-04\n",
      "Epoch 63/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.0620e-04\n",
      "Epoch 64/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.4410e-04\n",
      "Epoch 65/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.7508e-04\n",
      "Epoch 66/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.9257e-04\n",
      "Epoch 67/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.9929e-04\n",
      "Epoch 68/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 7.4340e-04\n",
      "Epoch 69/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 8.3307e-04\n",
      "Epoch 70/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.9429e-04\n",
      "Epoch 71/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 7.3942e-04\n",
      "Epoch 72/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.4747e-04\n",
      "Epoch 73/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.4468e-04\n",
      "Epoch 74/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.5564e-04\n",
      "Epoch 75/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.4405e-04\n",
      "Epoch 76/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.9479e-04\n",
      "Epoch 77/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 7.8766e-04\n",
      "Epoch 78/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.8094e-04\n",
      "Epoch 79/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.6417e-04\n",
      "Epoch 80/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.7229e-04\n",
      "Epoch 81/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.9563e-04\n",
      "Epoch 82/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.1703e-04\n",
      "Epoch 83/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.0280e-04\n",
      "Epoch 84/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.8091e-04\n",
      "Epoch 85/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.2839e-04\n",
      "Epoch 86/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.6124e-04\n",
      "Epoch 87/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.1682e-04\n",
      "Epoch 88/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 5.9636e-04\n",
      "Epoch 89/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.8243e-04\n",
      "Epoch 90/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 7.0790e-04\n",
      "Epoch 91/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 5.5449e-04\n",
      "Epoch 92/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.0299e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2456/2456 [==============================] - 18s 7ms/step - loss: 5.7211e-04\n",
      "Epoch 94/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 5.6146e-04\n",
      "Epoch 95/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.0059e-04\n",
      "Epoch 96/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.5816e-04\n",
      "Epoch 97/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.5374e-04\n",
      "Epoch 98/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 5.8760e-04\n",
      "Epoch 99/100\n",
      "2456/2456 [==============================] - 18s 7ms/step - loss: 6.4308e-04\n",
      "Epoch 100/100\n",
      "2456/2456 [==============================] - 19s 8ms/step - loss: 6.1874e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10dbff4a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_set, labels, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_features)\n",
    "predictions = scaler.inverse_transform(predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))  \n",
    "plt.plot(mm, color='blue', label='Actual')  \n",
    "plt.plot(predictions , color='red', label='Predicted')    \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
